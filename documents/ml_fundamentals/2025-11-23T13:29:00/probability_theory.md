# **ML Fundamental: 확률 및 통계 기반 핵심 개념**

머신러닝 모델의 성능을 이해하고 디버깅하며, 데이터의 잠재적인 문제를 파악하는 데 필요한 통계적 기초 지식입니다.

## **1\. I.I.D. 가정 (Independent and Identically Distributed)**

### **A. 정의 및 중요성**

\*\*I.I.D. (독립적이고 동일하게 분포된)\*\*는 대부분의 전통적인 통계 및 머신러닝 알고리즘이 성공적으로 작동하기 위해 전제로 하는 가장 기본적인 가정입니다.

* **독립적 (Independent):** 데이터셋 내의 각 관측치(샘플)가 다른 관측치에 영향을 미치지 않습니다. 즉, 한 샘플의 확률 분포는 다른 샘플이 관측되었는지 여부와 무관합니다.
* **동일하게 분포된 (Identically Distributed):** 모든 관측치가 동일한 근본적인 확률 분포 $P(X)$를 따릅니다. 이는 학습 데이터와 테스트 데이터가 같은 환경에서 추출되었음을 의미합니다.

**왜 중요한가?** I.I.D. 가정이 충족될 때, 우리는 학습 데이터로 추정한 통계량(평균, 분산 등)과 학습된 모델의 성능이 테스트 데이터에서도 유사하게 유지될 것이라고 확신할 수 있습니다 (일반화 보장).

### **B. 실제 환경에서의 I.I.D. 위반 사례**

광고 플랫폼 환경과 같이 시계열 데이터를 다루는 곳에서는 I.I.D. 가정이 쉽게 깨집니다.

1. **독립성 위반 (시계열 데이터):** 어제 발생한 사용자의 이벤트는 오늘 발생할 이벤트에 영향을 미칩니다 (예: 어제 클릭한 광고는 오늘 다시 클릭할 확률에 영향을 줌). 이는 데이터가 독립적이지 않고 **시간적 종속성**을 가진다는 것을 의미합니다.
2. **동일 분포 위반 (데이터 드리프트):** 시간이 지남에 따라 사용자 행동 패턴(예: 쇼핑 트렌드)이나 데이터 수집 방식이 변경되어 데이터 분포가 달라지는 **데이터 드리프트(Data Drift)** 현상이 발생합니다. 이는 더 이상 동일한 분포를 따르지 않는다는 의미입니다.

## **2\. 확률 변수 (Random Variable, RV)**

### **A. 정의와 역할**

**확률 변수**는 확률 실험의 결과를 실수 값에 대응시키는 함수입니다. 이는 복잡한 실제 사건을 수학적으로 다룰 수 있도록 변환하는 역할을 합니다.

* **이산 확률 변수 (Discrete RV):** 셀 수 있는 유한하거나 가산 무한한 값만 취하는 변수입니다.
  * *예시:* CTR 예측 모델의 결과(클릭/비클릭), 주사위 눈금.
* **연속 확률 변수 (Continuous RV):** 특정 구간 내의 모든 실수 값을 취할 수 있는 변수입니다.
  * *예시:* 광고 입찰가, 사용자 체류 시간, 예측된 확률 값(0.0에서 1.0 사이).

### **B. 주요 통계량**

확률 변수를 설명하는 핵심 통계량입니다.

* **기댓값 (Expectation,** $\mu$**):** 확률 변수가 취할 수 있는 값들을 확률에 따라 가중 평균한 값입니다. 장기적으로 실험을 반복했을 때 얻을 수 있는 평균 결과로 해석됩니다.
* **분산 (Variance,** $\sigma^2$**):** 확률 변수가 기댓값으로부터 얼마나 넓게 퍼져 있는지를 나타내는 척도입니다. 분산이 클수록 불확실성(Uncertainty)이 높습니다.

## **3\. 다변량 정규 분포 (Multivariate Normal Distribution, MND)**

### **A. 정의 및 구조**

다변량 정규 분포는 여러 확률 변수들의 결합 분포를 설명하는 데 사용되며, 통계적 모델링에서 가장 기본이 되는 분포 중 하나입니다. $p$차원 벡터 $\mathbf{X} = (X_1, X_2, \ldots, X_p)^T$의 확률 밀도 함수를 정의합니다.

* **핵심 매개변수:**
  1. **평균 벡터 (**$\boldsymbol{\mu}$**):** 각 변수($X_i$)의 평균으로 구성된 벡터입니다.
  2. **공분산 행렬 (**$\mathbf{\Sigma}$**):** 변수들 간의 상호 관계를 정의하는 행렬입니다.

$$\mathbf{X} \sim N_p(\boldsymbol{\mu}, \mathbf{\Sigma})$$


### **B. 공분산 행렬 ($\mathbf{\Sigma}$)의 역할**

공분산 행렬은 MND의 형태와 방향을 결정합니다.

* **대각 성분:** 각 변수 $X_i$의 \*\*분산($\sigma_i^2$)\*\*이 위치합니다.
* **비대각 성분:** 두 변수 $X_i$와 $X_j$ 간의 \*\*공분산($\text{Cov}(X_i, X_j)$)\*\*이 위치합니다. 공분산이 0이면 두 변수는 선형 독립입니다 (MND에서는 독립과 무상관이 동치).
* **시각적 해석:** MND의 등고선(Contour) 형태는 공분산 행렬에 의해 결정됩니다. 공분산이 클수록 등고선이 대각선 방향으로 길게 늘어지며, 이는 두 변수 사이에 강한 상관관계가 있음을 의미합니다.

## **4\. 이상치 탐지 (Outlier Detection)**

### **A. 이상치의 정의 및 영향**

\*\*이상치(Outlier)\*\*는 데이터의 나머지 관측치들과 현저하게 동떨어져 보이는 관측치입니다. 이상치는 모델의 학습 과정에 심각한 편향을 유발하여 일반화 성능을 저해할 수 있습니다.

* *예시:* 광고 클릭 데이터에서 특정 봇(Bot)이 비정상적으로 짧은 시간 안에 수천 번의 클릭을 발생시키는 경우.

### **B. 이상치 탐지 기법**

이상치 탐지는 크게 통계 기반, 거리 기반, 밀도 기반, 그리고 ML 기반 방법으로 나뉩니다.

1. **통계 기반 (Statistical Methods):**
   * **3-시그마/IQR Rule:** 단변량 데이터에서 평균으로부터 3표준편차 이상 떨어져 있거나 IQR(Interquartile Range) 기준을 초과하는 데이터를 이상치로 간주합니다.
   * **다변량 정규 분포 활용:** MND 가정 하에서, \*\*마할라노비스 거리(Mahalanobis Distance)\*\*를 계산하여 이상치를 탐지합니다. 마할라노비스 거리는 단순히 유클리드 거리를 측정하는 것이 아니라, \*\*변수 간의 상관관계(공분산 행렬)\*\*를 고려하여 데이터 분포의 중심으로부터 떨어진 정도를 측정합니다. 거리가 특정 임계값(예: 카이제곱 분포의 분위수)을 초과하면 이상치로 간주합니다.
2. **ML 기반 (ML/Proximity Methods):**
   * **밀도 기반 (Local Outlier Factor, LOF):** 주변 이웃들과의 밀도를 비교하여, 주변보다 현저히 밀도가 낮은 관측치를 이상치로 판단합니다.
   * **거리 기반 (k-Nearest Neighbors, k-NN):** 가장 가까운 $k$개의 이웃까지의 거리가 멀수록 이상치일 확률이 높다고 판단합니다.
   * **앙상블 기반 (Isolation Forest):** 데이터를 무작위로 분할했을 때, 이상치(Outlier)가 정상 데이터보다 더 적은 분할 횟수로 고립된다는 점을 이용합니다.

## **5\. 예상 객관식/단답형 질문 (Self-Test)**

1. **질문:** **광고 플랫폼 기업**의 CTR 예측 모델을 학습시킬 때, **I.I.D. 가정이 깨지는 가장 흔한 이유** 두 가지를 제시하고 이것이 모델 성능에 미치는 영향을 설명하세요.
   * **답변 예시:** 1\) **독립성 위반:** 시간적 종속성을 가지는 사용자 행동 데이터. 2\) **동일 분포 위반:** 사용자 트렌드의 변화로 인한 데이터 드리프트. 영향은 학습된 모델이 현재의 데이터를 정확히 예측하지 못하고(일반화 성능 저하), 지속적인 재학습이 필요하다는 것입니다.
2. **질문:** 다변량 정규 분포에서 **공분산 행렬의 비대각 성분이 모두 0**일 경우, 이 행렬은 어떤 특징을 가지며 이는 확률 변수에 대해 어떤 통계적 의미를 부여하나요?
   * **답변 예시:** 공분산 행렬은 대각 행렬이 되며, 이는 모든 변수 쌍 사이의 **공분산이 0**임을 의미합니다. 다변량 정규 분포 가정 하에서는 공분산이 0인 것은 \*\*변수들이 서로 독립적(Independent)\*\*임을 의미합니다.
3. **질문:** 단변량 데이터의 이상치 탐지에서 널리 사용되는 3-시그마 규칙 대신, 다변량 데이터에서 이상치를 탐지할 때 **마할라노비스 거리**를 사용하는 이유를 설명하세요.
   * **답변 예시:** 3-시그마 규칙은 각 변수의 분산만 고려하지만, 마할라노비스 거리는 \*\*변수들 간의 상관관계(공분산)\*\*를 함께 고려합니다. 두 변수 사이에 강한 상관관계가 있을 때, 마할라노비스 거리는 이 상관관계를 벗어나는 이상치를 더 정확하게 식별할 수 있습니다.
