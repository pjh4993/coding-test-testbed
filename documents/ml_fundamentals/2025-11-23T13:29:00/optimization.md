# **ML Fundamental: 최적화 및 고전 알고리즘**

이 섹션은 모델 학습의 핵심인 **최적화 알고리즘**의 작동 원리와 **고전 알고리즘**의 내부 메커니즘을 다룹니다. 이는 모델을 단순히 사용하는 것을 넘어, 학습 과정을 깊이 있게 이해하고 디버깅하는 데 필수적입니다.

## **1\. 최적화 알고리즘 (Optimization Algorithms)**

최적화는 \*\*손실 함수(Loss Function)\*\*의 값을 최소화하는 모델의 파라미터(가중치와 편향)를 찾는 과정입니다.

### **A. 경사 하강법 (Gradient Descent, GD)**

GD는 파라미터 $\theta$를 손실 함수 $J(\theta)$의 현재 기울기(Gradient) 반대 방향으로 학습률($\eta$)만큼 이동시키며 업데이트하는 알고리즘입니다.

$$\theta := \theta - \eta \nabla J(\theta)$$

| 종류 | 특징 | 기울기 분산(Noise) | 수렴 속도 |
| :---- | :---- | :---- | :---- |
| **배치 GD (Batch GD)** | **전체** 데이터셋의 기울기를 계산 | **낮음** (안정적인 참 기울기) | 느림 (전체 데이터 연산) |
| **확률적 GD (Stochastic GD, SGD)** | **샘플 1개**의 기울기를 계산 | **매우 높음** (노이즈 많음) | 매우 빠름, Local Minimum 탈출 용이 |
| **미니 배치 GD (Mini-Batch GD)** | $N$개의 샘플($N > 1$) 기울기를 계산 | 중간 | GD와 SGD의 절충안, 가장 일반적으로 사용됨 |

**GD의 학습률 (**$\eta$**) 중요성:** 학습률은 최적화 과정에서 '보폭'을 결정합니다. 너무 작으면 수렴이 오래 걸리고, 너무 크면 손실 함수 최솟값을 지나쳐 발산할 수 있습니다. GD의 성능은 이 $\eta$와 초기 파라미터 $\theta$ 설정에 크게 의존합니다.

### **B. 고급 최적화 기법 (Q5 관련)**

SGD의 단점(높은 분산, 느린 수렴)을 개선하고 Local Minimum 회피 능력을 강화하기 위해 고급 기법이 개발되었습니다.

1. **모멘텀 (Momentum):** 이전 업데이트의 방향($v$)을 고려하여 현재 업데이트에 관성을 부여합니다. 이는 손실 함수의 계곡을 따라 내려갈 때 발생하는 불필요한 진동을 줄이고, 일관된 방향으로 더 빠르게 이동하도록 돕습니다.
   * **효과:** 진폭이 심한 지역에서 Local Minimum을 지나쳐 안정적으로 빠져나갈 수 있도록 하며, 수렴 속도를 높입니다.
   * **수학적 아이디어:** 물리학의 관성 개념을 도입하여 기울기 방향뿐 아니라 **움직임의 역사**를 반영합니다.
2. **Adam (Adaptive Moment Estimation):** 가장 널리 사용되는 최적화 기법입니다.
   * **작동 원리:** Adam은 두 가지 '이동 평균(Moment)'을 사용합니다.
     * **1차 모멘트 (**$m$**):** Momentum처럼 이전 기울기를 고려합니다. (방향성 유지)
     * **2차 모멘트 (**$v$**):** 이전 기울기의 **제곱**을 고려하여 각 파라미터의 \*\*기울기 크기 변동성(분산)\*\*을 추정합니다.
   * **적응적 학습률:** 이 두 모멘트를 사용하여 각 파라미터마다 \*\*적응적인 학습률(Adaptive Learning Rate)\*\*을 적용합니다. 빈번하게 업데이트되는 피처(큰 기울기)는 학습률을 낮추고, 희소한 피처(작은 기울기)는 학습률을 높여 효율성을 극대화합니다.
* **Local Minimum 회피 (Q5 해설):**
  * Gradient Descent는 이론적으로 Local Minimum에 수렴하지만, 실제 딥러닝에서 SGD나 Adam 같은 **확률적** 최적화 기법은 **미니 배치에서 발생하는 노이즈(불안정한 기울기)** 덕분에 좁은 Local Minimum이나 안장점(Saddle Point)을 뛰어넘는 경향이 있습니다.
  * 특히 **Weight Initialization을 잘 설정**하여 초기 파라미터를 손실 함수의 '평평한(Flat)' 영역(최적점에 가까운)으로 설정하는 것이 중요합니다.

## **2\. 정규화 (Regularization)의 상세 원리 (Q3 관련)**

정규화는 모델의 복잡도(가중치 크기)에 패널티를 부여하여 Overfitting을 방지하고 일반화 성능을 높입니다.

### **A. L1 Regularization (Lasso)**

손실 함수 $J(\theta)$에 **가중치(**$w$**)의 절댓값의 합**을 패널티로 추가합니다.

$$J(\theta) + \lambda \sum_{i} |w_i|$$

* **특성 (Q3 해설):** L1의 제약 영역은 **마름모 형태**입니다. L1의 최적화 해는 종종 \*\*축(Axis)\*\*에 닿게 되며, 이는 일부 가중치를 **정확히 0**으로 만듭니다. 이로 인해 **덜 중요한 피처의 가중치를 실제로 0으로 만들고** 제거하는 **Feature Selection 효과**가 있습니다. 모델을 희소(Sparse)하게 만듭니다.

### **B. L2 Regularization (Ridge)**

손실 함수 $J(\theta)$에 **가중치(**$w$**)의 제곱의 합**을 패널티로 추가합니다.

$$J(\theta) + \lambda \sum_{i} w_i^2$$

* **특성:** L2의 제약 영역은 **원 형태**입니다. L2는 가중치를 0에 가깝게 수축시키지만, **실제로 0으로 만들지는 않습니다.** 대신, L2는 가중치들의 크기를 전반적으로 줄여 모델을 단순화하고, **다중 공선성(Multicollinearity) 문제를 완화**하는 데 효과적입니다.

#### **L2가 다중 공선성을 완화하는 원리 (심화)**

1\. 다중 공선성의 문제:
다중 공선성은 두 개 이상의 피처가 서로 높은 상관관계를 가질 때 발생합니다. 이 경우, OLS(Ordinary Least Squares)와 같은 선형 회귀는 해가 불안정해집니다. 즉, 데이터의 작은 변동에도 불구하고 가중치($w$) 추정값이 매우 크게(때로는 양극단으로) 변동하며, 두 상관 피처의 중요도를 임의로 나누어 가지기 때문에 해석이 어려워집니다. 손실 함수 그래프는 극도로 길고 좁은 타원형 계곡 형태를 띱니다.
2\. L2 제약의 안정화 역할:
L2 정규화는 손실 함수에 $\lambda$만큼의 항을 더함으로써 모델의 해를 찾을 때 무조건적으로 가중치 벡터의 크기를 줄이도록 강제합니다.

* **기하학적 해석:** 손실 함수의 좁고 긴 타원형 등고선이 L2의 **원형 제약 영역**에 접하는 해를 찾게 됩니다. 이 접점은 타원의 가장자리(OLS 해)보다 \*\*원점(가중치 0)\*\*에 훨씬 가깝게 위치합니다.
* **효과:** L2는 상관 피처들의 가중치를 **골고루, 그리고 작게** 분산시키는 경향이 있습니다 (예: OLS가 $w_1=10, w_2=-10$을 선택할 때, L2는 $w_1=5, w_2=5$를 선호). 이로 인해 추정된 가중치 벡터의 \*\*분산(Variance)\*\*이 크게 줄어들어 해가 \*\*안정적(Stable)\*\*이 되며, 다중 공선성으로 인한 가중치의 극단적인 변동을 완화합니다.

### **C. 드롭아웃 (Dropout)**

딥러닝 모델에서 주로 사용되는 정규화 기법입니다.

* **작동 원리:** 학습 단계에서 각 뉴런을 \*\*확률 $p$\*\*로 임의로 제거(Drop Out)하여 활성화를 중지시킵니다.
* **효과:** 매 학습 단계마다 **다른 신경망 구조**를 사용하게 되므로, 뉴런들이 특정 피처에 과하게 의존하는 \*\*공동 적응(Co-adaptation)\*\*을 방지합니다. 이는 마치 무작위로 생성된 앙상블 모델을 학습하는 것과 유사한 효과를 가져와 일반화 성능을 높입니다. 추론 시에는 모든 뉴런을 사용하지만, 학습 시 사용된 드롭아웃 확률만큼 가중치를 줄여줍니다.

## **3\. 고전 알고리즘의 내부 원리**

### **A. 결정 트리 (Decision Tree) 및 앙상블 (Ensemble)**

* **Gini Impurity (Q19 해설):** 결정 트리에서 \*\*노드가 얼마나 불순한지(섞여 있는지)\*\*를 측정하는 지표입니다. 불순도가 낮을수록 해당 노드가 한 클래스를 더 잘 대표합니다. 트리는 Gini Impurity를 최소화하는 방향으로 분할됩니다.

$$\text{Gini Impurity} = 1 - \sum_{i=1}^{C} p_i^2$$

($p_i$는 해당 노드에서 클래스 $i$에 속하는 샘플의 비율)

* **Entropy (보충):** Gini Impurity와 함께 불순도를 측정하는 또 다른 지표입니다.$$ Entropy = - \sum_{i=1}^{C} p_i \log_2(p_i)$$
  * **실무적 선택:** Entropy가 이론적으로 더 엄격하지만, Gini Impurity가 계산이 더 간단하고 빠르기 때문에 실제 Decision Tree 구현(예: Scikit-learn의 기본값)에서 자주 선호됩니다.
* **Random Forest (Q6 해설):** 다수의 결정 트리를 독립적으로 학습시킨 후, 투표를 통해 최종 결과를 결정하는 **배깅(Bagging)** 앙상블 기법입니다.
  * **Overfitting 감소 이유 2가지:**
    1. **데이터 샘플링 (Bootstrap Aggregating):** 각 트리가 원래 데이터셋에서 **복원 추출된(Bootstrap)** 데이터 샘플로 학습되어 트리가 서로 다르게 만듭니다. 이로 인해 트리의 \*\*분산(Variance)\*\*을 줄입니다.
    2. **피처 샘플링:** 각 분할 시점에 무작위로 추출된 피처의 부분 집합만 고려하여, 트리의 상관관계(Correlation)를 낮춥니다. 이 두 가지 무작위성이 트리를 다양하게 만들어 과적합을 방지합니다.

### **B. 거리 기반 알고리즘과 피처 스케일링 (Q7 해설)**

* **Feature Scaling의 필요성 (Q7 해설):** KNN, SVM, Logistic Regression과 같은 알고리즘은 **피처 간의 거리를 측정**하거나, **경사 하강법**을 사용하여 최적화합니다.
  * **거리 측정의 왜곡 (KNN, SVM):** 피처 스케일이 다르면(예: 키(cm)와 나이(년)) 스케일이 큰 피처(키)가 거리에 **압도적인 영향**을 미쳐 다른 피처의 중요성을 무시하게 됩니다. 스케일링은 모든 피처가 동일한 중요도를 갖도록 보장합니다.
  * **경사 하강의 비효율성 (LR, NN):** 스케일이 다르면 손실 함수의 등고선이 심한 타원형이 되어 최적화 경로가 지그재그로 길어지고 수렴이 느려집니다.
* **Decision Tree의 면역성:** **Feature Scaling이 불필요한 대표적인 알고리즘**입니다. Decision Tree는 데이터를 분할하는 **임계값**만 사용하며, 피처의 값의 크기나 분산이 분할 결정에 영향을 미치지 않습니다.

## **4\. 군집화 알고리즘의 핵심 (K-Means, Q17 관련)**

K-Means는 대표적인 비지도 학습(Unsupervised Learning) 알고리즘으로, 데이터를 $K$개의 군집으로 분할합니다.

* **EM (Expectation-Maximization) 원리:** K-Means는 EM 알고리즘의 한 형태입니다.
  1. **E-Step (Expectation):** 각 데이터 포인트가 현재의 **Centroid(**$\mu_k$**)에 가장 가까운 군집**을 할당받습니다. (거리 기반)
  2. **M-Step (Maximization, Q17 해설):** 각 군집에 할당된 모든 데이터 포인트를 사용하여 **새로운 Centroid(**$\mu_k$**)를 계산**하여 업데이트합니다. 이 새로운 Centroid는 해당 군집에 속한 모든 데이터 포인트의 **평균 벡터**입니다.

$$\text{Centroid} \mu_k = \frac{1}{|C_k|} \sum_{x_i \in C_k} x_i$$

* $|C_k|$는 $k$번째 군집에 속한 데이터 포인트의 개수입니다.
